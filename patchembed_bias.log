Current host is: june
save path : /data1/Xuan_vit_ckp/2024-03-19/cifar10_deit_base_cifar100_head_0_AdamW
{'arch': 'deit_base_cifar100_head', 'attack_sample_size': 128, 'data_path': '/data1/', 'dataset': 'cifar10', 'decay': 0.0001, 'enable_bfa': True, 'epochs': 0, 'evaluate': True, 'fine_tune': False, 'gammas': [0.1, 0.1], 'gpu_id': 0, 'k_top': 10, 'learning_rate': 0.001, 'manualSeed': 1, 'model_name': 'deit_base_cifar100_head', 'model_only': False, 'momentum': 0.9, 'n_iter': 1, 'ngpu': 2, 'optimize_step': False, 'optimizer': 'AdamW', 'print_freq': 1, 'reset_weight': True, 'resume': '', 'save_path': '/data1/Xuan_vit_ckp/2024-03-19/cifar10_deit_base_cifar100_head_0_AdamW', 'schedule': [80, 120], 'sparsity': 'None', 'sparsity_th': 0.0, 'start_epoch': 0, 'test_batch_size': 256, 'use_cuda': True, 'workers': 8}
Random Seed: 1
python version : 3.6.13 |Anaconda, Inc.| (default, Jun  4 2021, 14:25:59)  [GCC 7.5.0]
torch  version : 1.8.1
cudnn  version : 8005
Files already downloaded and verified
Files already downloaded and verified
=> creating model 'deit_base_cifar100_head'
====================== There are 10 class
cls_token: shape = torch.Size([1, 1, 768]), number of weights = 768
pos_embed: shape = torch.Size([1, 197, 768]), number of weights = 151296
patch_embed.proj.weight: shape = torch.Size([768, 3, 16, 16]), number of weights = 589824
patch_embed.proj.bias: shape = torch.Size([768]), number of weights = 768
blocks.0.norm1.weight: shape = torch.Size([768]), number of weights = 768
blocks.0.norm1.bias: shape = torch.Size([768]), number of weights = 768
blocks.0.attn.qkv.weight: shape = torch.Size([2304, 768]), number of weights = 1769472
blocks.0.attn.qkv.bias: shape = torch.Size([2304]), number of weights = 2304
blocks.0.attn.proj.weight: shape = torch.Size([768, 768]), number of weights = 589824
blocks.0.attn.proj.bias: shape = torch.Size([768]), number of weights = 768
blocks.0.norm2.weight: shape = torch.Size([768]), number of weights = 768
blocks.0.norm2.bias: shape = torch.Size([768]), number of weights = 768
blocks.0.mlp.fc1.weight: shape = torch.Size([3072, 768]), number of weights = 2359296
blocks.0.mlp.fc1.bias: shape = torch.Size([3072]), number of weights = 3072
blocks.0.mlp.fc2.weight: shape = torch.Size([768, 3072]), number of weights = 2359296
blocks.0.mlp.fc2.bias: shape = torch.Size([768]), number of weights = 768
blocks.1.norm1.weight: shape = torch.Size([768]), number of weights = 768
blocks.1.norm1.bias: shape = torch.Size([768]), number of weights = 768
blocks.1.attn.qkv.weight: shape = torch.Size([2304, 768]), number of weights = 1769472
blocks.1.attn.qkv.bias: shape = torch.Size([2304]), number of weights = 2304
blocks.1.attn.proj.weight: shape = torch.Size([768, 768]), number of weights = 589824
blocks.1.attn.proj.bias: shape = torch.Size([768]), number of weights = 768
blocks.1.norm2.weight: shape = torch.Size([768]), number of weights = 768
blocks.1.norm2.bias: shape = torch.Size([768]), number of weights = 768
blocks.1.mlp.fc1.weight: shape = torch.Size([3072, 768]), number of weights = 2359296
blocks.1.mlp.fc1.bias: shape = torch.Size([3072]), number of weights = 3072
blocks.1.mlp.fc2.weight: shape = torch.Size([768, 3072]), number of weights = 2359296
blocks.1.mlp.fc2.bias: shape = torch.Size([768]), number of weights = 768
blocks.2.norm1.weight: shape = torch.Size([768]), number of weights = 768
blocks.2.norm1.bias: shape = torch.Size([768]), number of weights = 768
blocks.2.attn.qkv.weight: shape = torch.Size([2304, 768]), number of weights = 1769472
blocks.2.attn.qkv.bias: shape = torch.Size([2304]), number of weights = 2304
blocks.2.attn.proj.weight: shape = torch.Size([768, 768]), number of weights = 589824
blocks.2.attn.proj.bias: shape = torch.Size([768]), number of weights = 768
blocks.2.norm2.weight: shape = torch.Size([768]), number of weights = 768
blocks.2.norm2.bias: shape = torch.Size([768]), number of weights = 768
blocks.2.mlp.fc1.weight: shape = torch.Size([3072, 768]), number of weights = 2359296
blocks.2.mlp.fc1.bias: shape = torch.Size([3072]), number of weights = 3072
blocks.2.mlp.fc2.weight: shape = torch.Size([768, 3072]), number of weights = 2359296
blocks.2.mlp.fc2.bias: shape = torch.Size([768]), number of weights = 768
blocks.3.norm1.weight: shape = torch.Size([768]), number of weights = 768
blocks.3.norm1.bias: shape = torch.Size([768]), number of weights = 768
blocks.3.attn.qkv.weight: shape = torch.Size([2304, 768]), number of weights = 1769472
blocks.3.attn.qkv.bias: shape = torch.Size([2304]), number of weights = 2304
blocks.3.attn.proj.weight: shape = torch.Size([768, 768]), number of weights = 589824
blocks.3.attn.proj.bias: shape = torch.Size([768]), number of weights = 768
blocks.3.norm2.weight: shape = torch.Size([768]), number of weights = 768
blocks.3.norm2.bias: shape = torch.Size([768]), number of weights = 768
blocks.3.mlp.fc1.weight: shape = torch.Size([3072, 768]), number of weights = 2359296
blocks.3.mlp.fc1.bias: shape = torch.Size([3072]), number of weights = 3072
blocks.3.mlp.fc2.weight: shape = torch.Size([768, 3072]), number of weights = 2359296
blocks.3.mlp.fc2.bias: shape = torch.Size([768]), number of weights = 768
blocks.4.norm1.weight: shape = torch.Size([768]), number of weights = 768
blocks.4.norm1.bias: shape = torch.Size([768]), number of weights = 768
blocks.4.attn.qkv.weight: shape = torch.Size([2304, 768]), number of weights = 1769472
blocks.4.attn.qkv.bias: shape = torch.Size([2304]), number of weights = 2304
blocks.4.attn.proj.weight: shape = torch.Size([768, 768]), number of weights = 589824
blocks.4.attn.proj.bias: shape = torch.Size([768]), number of weights = 768
blocks.4.norm2.weight: shape = torch.Size([768]), number of weights = 768
blocks.4.norm2.bias: shape = torch.Size([768]), number of weights = 768
blocks.4.mlp.fc1.weight: shape = torch.Size([3072, 768]), number of weights = 2359296
blocks.4.mlp.fc1.bias: shape = torch.Size([3072]), number of weights = 3072
blocks.4.mlp.fc2.weight: shape = torch.Size([768, 3072]), number of weights = 2359296
blocks.4.mlp.fc2.bias: shape = torch.Size([768]), number of weights = 768
blocks.5.norm1.weight: shape = torch.Size([768]), number of weights = 768
blocks.5.norm1.bias: shape = torch.Size([768]), number of weights = 768
blocks.5.attn.qkv.weight: shape = torch.Size([2304, 768]), number of weights = 1769472
blocks.5.attn.qkv.bias: shape = torch.Size([2304]), number of weights = 2304
blocks.5.attn.proj.weight: shape = torch.Size([768, 768]), number of weights = 589824
blocks.5.attn.proj.bias: shape = torch.Size([768]), number of weights = 768
blocks.5.norm2.weight: shape = torch.Size([768]), number of weights = 768
blocks.5.norm2.bias: shape = torch.Size([768]), number of weights = 768
blocks.5.mlp.fc1.weight: shape = torch.Size([3072, 768]), number of weights = 2359296
blocks.5.mlp.fc1.bias: shape = torch.Size([3072]), number of weights = 3072
blocks.5.mlp.fc2.weight: shape = torch.Size([768, 3072]), number of weights = 2359296
blocks.5.mlp.fc2.bias: shape = torch.Size([768]), number of weights = 768
blocks.6.norm1.weight: shape = torch.Size([768]), number of weights = 768
blocks.6.norm1.bias: shape = torch.Size([768]), number of weights = 768
blocks.6.attn.qkv.weight: shape = torch.Size([2304, 768]), number of weights = 1769472
blocks.6.attn.qkv.bias: shape = torch.Size([2304]), number of weights = 2304
blocks.6.attn.proj.weight: shape = torch.Size([768, 768]), number of weights = 589824
blocks.6.attn.proj.bias: shape = torch.Size([768]), number of weights = 768
blocks.6.norm2.weight: shape = torch.Size([768]), number of weights = 768
blocks.6.norm2.bias: shape = torch.Size([768]), number of weights = 768
blocks.6.mlp.fc1.weight: shape = torch.Size([3072, 768]), number of weights = 2359296
blocks.6.mlp.fc1.bias: shape = torch.Size([3072]), number of weights = 3072
blocks.6.mlp.fc2.weight: shape = torch.Size([768, 3072]), number of weights = 2359296
blocks.6.mlp.fc2.bias: shape = torch.Size([768]), number of weights = 768
blocks.7.norm1.weight: shape = torch.Size([768]), number of weights = 768
blocks.7.norm1.bias: shape = torch.Size([768]), number of weights = 768
blocks.7.attn.qkv.weight: shape = torch.Size([2304, 768]), number of weights = 1769472
blocks.7.attn.qkv.bias: shape = torch.Size([2304]), number of weights = 2304
blocks.7.attn.proj.weight: shape = torch.Size([768, 768]), number of weights = 589824
blocks.7.attn.proj.bias: shape = torch.Size([768]), number of weights = 768
blocks.7.norm2.weight: shape = torch.Size([768]), number of weights = 768
blocks.7.norm2.bias: shape = torch.Size([768]), number of weights = 768
blocks.7.mlp.fc1.weight: shape = torch.Size([3072, 768]), number of weights = 2359296
blocks.7.mlp.fc1.bias: shape = torch.Size([3072]), number of weights = 3072
blocks.7.mlp.fc2.weight: shape = torch.Size([768, 3072]), number of weights = 2359296
blocks.7.mlp.fc2.bias: shape = torch.Size([768]), number of weights = 768
blocks.8.norm1.weight: shape = torch.Size([768]), number of weights = 768
blocks.8.norm1.bias: shape = torch.Size([768]), number of weights = 768
blocks.8.attn.qkv.weight: shape = torch.Size([2304, 768]), number of weights = 1769472
blocks.8.attn.qkv.bias: shape = torch.Size([2304]), number of weights = 2304
blocks.8.attn.proj.weight: shape = torch.Size([768, 768]), number of weights = 589824
blocks.8.attn.proj.bias: shape = torch.Size([768]), number of weights = 768
blocks.8.norm2.weight: shape = torch.Size([768]), number of weights = 768
blocks.8.norm2.bias: shape = torch.Size([768]), number of weights = 768
blocks.8.mlp.fc1.weight: shape = torch.Size([3072, 768]), number of weights = 2359296
blocks.8.mlp.fc1.bias: shape = torch.Size([3072]), number of weights = 3072
blocks.8.mlp.fc2.weight: shape = torch.Size([768, 3072]), number of weights = 2359296
blocks.8.mlp.fc2.bias: shape = torch.Size([768]), number of weights = 768
blocks.9.norm1.weight: shape = torch.Size([768]), number of weights = 768
blocks.9.norm1.bias: shape = torch.Size([768]), number of weights = 768
blocks.9.attn.qkv.weight: shape = torch.Size([2304, 768]), number of weights = 1769472
blocks.9.attn.qkv.bias: shape = torch.Size([2304]), number of weights = 2304
blocks.9.attn.proj.weight: shape = torch.Size([768, 768]), number of weights = 589824
blocks.9.attn.proj.bias: shape = torch.Size([768]), number of weights = 768
blocks.9.norm2.weight: shape = torch.Size([768]), number of weights = 768
blocks.9.norm2.bias: shape = torch.Size([768]), number of weights = 768
blocks.9.mlp.fc1.weight: shape = torch.Size([3072, 768]), number of weights = 2359296
blocks.9.mlp.fc1.bias: shape = torch.Size([3072]), number of weights = 3072
blocks.9.mlp.fc2.weight: shape = torch.Size([768, 3072]), number of weights = 2359296
blocks.9.mlp.fc2.bias: shape = torch.Size([768]), number of weights = 768
blocks.10.norm1.weight: shape = torch.Size([768]), number of weights = 768
blocks.10.norm1.bias: shape = torch.Size([768]), number of weights = 768
blocks.10.attn.qkv.weight: shape = torch.Size([2304, 768]), number of weights = 1769472
blocks.10.attn.qkv.bias: shape = torch.Size([2304]), number of weights = 2304
blocks.10.attn.proj.weight: shape = torch.Size([768, 768]), number of weights = 589824
blocks.10.attn.proj.bias: shape = torch.Size([768]), number of weights = 768
blocks.10.norm2.weight: shape = torch.Size([768]), number of weights = 768
blocks.10.norm2.bias: shape = torch.Size([768]), number of weights = 768
blocks.10.mlp.fc1.weight: shape = torch.Size([3072, 768]), number of weights = 2359296
blocks.10.mlp.fc1.bias: shape = torch.Size([3072]), number of weights = 3072
blocks.10.mlp.fc2.weight: shape = torch.Size([768, 3072]), number of weights = 2359296
blocks.10.mlp.fc2.bias: shape = torch.Size([768]), number of weights = 768
blocks.11.norm1.weight: shape = torch.Size([768]), number of weights = 768
blocks.11.norm1.bias: shape = torch.Size([768]), number of weights = 768
blocks.11.attn.qkv.weight: shape = torch.Size([2304, 768]), number of weights = 1769472
blocks.11.attn.qkv.bias: shape = torch.Size([2304]), number of weights = 2304
blocks.11.attn.proj.weight: shape = torch.Size([768, 768]), number of weights = 589824
blocks.11.attn.proj.bias: shape = torch.Size([768]), number of weights = 768
blocks.11.norm2.weight: shape = torch.Size([768]), number of weights = 768
blocks.11.norm2.bias: shape = torch.Size([768]), number of weights = 768
blocks.11.mlp.fc1.weight: shape = torch.Size([3072, 768]), number of weights = 2359296
blocks.11.mlp.fc1.bias: shape = torch.Size([3072]), number of weights = 3072
blocks.11.mlp.fc2.weight: shape = torch.Size([768, 3072]), number of weights = 2359296
blocks.11.mlp.fc2.bias: shape = torch.Size([768]), number of weights = 768
norm.weight: shape = torch.Size([768]), number of weights = 768
norm.bias: shape = torch.Size([768]), number of weights = 768
head.weight: shape = torch.Size([100, 768]), number of weights = 76800
head.bias: shape = torch.Size([100]), number of weights = 100
=================== Start changing layer type in deit_tiny_patch16_224_test in models/models.py =======================
=================== Complete changing conv2d/linear layers to quantized layers =======================
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))
    (norm): Identity()
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (norm_pre): Identity()
  (blocks): Sequential(
    (0): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU()
        (drop1): Dropout(p=0.0, inplace=False)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (1): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU()
        (drop1): Dropout(p=0.0, inplace=False)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (2): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU()
        (drop1): Dropout(p=0.0, inplace=False)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (3): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU()
        (drop1): Dropout(p=0.0, inplace=False)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (4): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU()
        (drop1): Dropout(p=0.0, inplace=False)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (5): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU()
        (drop1): Dropout(p=0.0, inplace=False)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (6): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU()
        (drop1): Dropout(p=0.0, inplace=False)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (7): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU()
        (drop1): Dropout(p=0.0, inplace=False)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (8): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU()
        (drop1): Dropout(p=0.0, inplace=False)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (9): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU()
        (drop1): Dropout(p=0.0, inplace=False)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (10): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU()
        (drop1): Dropout(p=0.0, inplace=False)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (11): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU()
        (drop1): Dropout(p=0.0, inplace=False)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  (fc_norm): Identity()
  (head): quan_Linear(in_features=768, out_features=100, bias=True)
)
ckp key = odict_keys(['module.cls_token', 'module.pos_embed', 'module.patch_embed.proj.weight', 'module.patch_embed.proj.step_size', 'module.patch_embed.proj.b_w', 'module.blocks.0.norm1.weight', 'module.blocks.0.norm1.bias', 'module.blocks.0.attn.qkv.weight', 'module.blocks.0.attn.qkv.bias', 'module.blocks.0.attn.qkv.step_size', 'module.blocks.0.attn.qkv.b_w', 'module.blocks.0.attn.proj.weight', 'module.blocks.0.attn.proj.bias', 'module.blocks.0.attn.proj.step_size', 'module.blocks.0.attn.proj.b_w', 'module.blocks.0.norm2.weight', 'module.blocks.0.norm2.bias', 'module.blocks.0.mlp.fc1.weight', 'module.blocks.0.mlp.fc1.bias', 'module.blocks.0.mlp.fc1.step_size', 'module.blocks.0.mlp.fc1.b_w', 'module.blocks.0.mlp.fc2.weight', 'module.blocks.0.mlp.fc2.bias', 'module.blocks.0.mlp.fc2.step_size', 'module.blocks.0.mlp.fc2.b_w', 'module.blocks.1.norm1.weight', 'module.blocks.1.norm1.bias', 'module.blocks.1.attn.qkv.weight', 'module.blocks.1.attn.qkv.bias', 'module.blocks.1.attn.qkv.step_size', 'module.blocks.1.attn.qkv.b_w', 'module.blocks.1.attn.proj.weight', 'module.blocks.1.attn.proj.bias', 'module.blocks.1.attn.proj.step_size', 'module.blocks.1.attn.proj.b_w', 'module.blocks.1.norm2.weight', 'module.blocks.1.norm2.bias', 'module.blocks.1.mlp.fc1.weight', 'module.blocks.1.mlp.fc1.bias', 'module.blocks.1.mlp.fc1.step_size', 'module.blocks.1.mlp.fc1.b_w', 'module.blocks.1.mlp.fc2.weight', 'module.blocks.1.mlp.fc2.bias', 'module.blocks.1.mlp.fc2.step_size', 'module.blocks.1.mlp.fc2.b_w', 'module.blocks.2.norm1.weight', 'module.blocks.2.norm1.bias', 'module.blocks.2.attn.qkv.weight', 'module.blocks.2.attn.qkv.bias', 'module.blocks.2.attn.qkv.step_size', 'module.blocks.2.attn.qkv.b_w', 'module.blocks.2.attn.proj.weight', 'module.blocks.2.attn.proj.bias', 'module.blocks.2.attn.proj.step_size', 'module.blocks.2.attn.proj.b_w', 'module.blocks.2.norm2.weight', 'module.blocks.2.norm2.bias', 'module.blocks.2.mlp.fc1.weight', 'module.blocks.2.mlp.fc1.bias', 'module.blocks.2.mlp.fc1.step_size', 'module.blocks.2.mlp.fc1.b_w', 'module.blocks.2.mlp.fc2.weight', 'module.blocks.2.mlp.fc2.bias', 'module.blocks.2.mlp.fc2.step_size', 'module.blocks.2.mlp.fc2.b_w', 'module.blocks.3.norm1.weight', 'module.blocks.3.norm1.bias', 'module.blocks.3.attn.qkv.weight', 'module.blocks.3.attn.qkv.bias', 'module.blocks.3.attn.qkv.step_size', 'module.blocks.3.attn.qkv.b_w', 'module.blocks.3.attn.proj.weight', 'module.blocks.3.attn.proj.bias', 'module.blocks.3.attn.proj.step_size', 'module.blocks.3.attn.proj.b_w', 'module.blocks.3.norm2.weight', 'module.blocks.3.norm2.bias', 'module.blocks.3.mlp.fc1.weight', 'module.blocks.3.mlp.fc1.bias', 'module.blocks.3.mlp.fc1.step_size', 'module.blocks.3.mlp.fc1.b_w', 'module.blocks.3.mlp.fc2.weight', 'module.blocks.3.mlp.fc2.bias', 'module.blocks.3.mlp.fc2.step_size', 'module.blocks.3.mlp.fc2.b_w', 'module.blocks.4.norm1.weight', 'module.blocks.4.norm1.bias', 'module.blocks.4.attn.qkv.weight', 'module.blocks.4.attn.qkv.bias', 'module.blocks.4.attn.qkv.step_size', 'module.blocks.4.attn.qkv.b_w', 'module.blocks.4.attn.proj.weight', 'module.blocks.4.attn.proj.bias', 'module.blocks.4.attn.proj.step_size', 'module.blocks.4.attn.proj.b_w', 'module.blocks.4.norm2.weight', 'module.blocks.4.norm2.bias', 'module.blocks.4.mlp.fc1.weight', 'module.blocks.4.mlp.fc1.bias', 'module.blocks.4.mlp.fc1.step_size', 'module.blocks.4.mlp.fc1.b_w', 'module.blocks.4.mlp.fc2.weight', 'module.blocks.4.mlp.fc2.bias', 'module.blocks.4.mlp.fc2.step_size', 'module.blocks.4.mlp.fc2.b_w', 'module.blocks.5.norm1.weight', 'module.blocks.5.norm1.bias', 'module.blocks.5.attn.qkv.weight', 'module.blocks.5.attn.qkv.bias', 'module.blocks.5.attn.qkv.step_size', 'module.blocks.5.attn.qkv.b_w', 'module.blocks.5.attn.proj.weight', 'module.blocks.5.attn.proj.bias', 'module.blocks.5.attn.proj.step_size', 'module.blocks.5.attn.proj.b_w', 'module.blocks.5.norm2.weight', 'module.blocks.5.norm2.bias', 'module.blocks.5.mlp.fc1.weight', 'module.blocks.5.mlp.fc1.bias', 'module.blocks.5.mlp.fc1.step_size', 'module.blocks.5.mlp.fc1.b_w', 'module.blocks.5.mlp.fc2.weight', 'module.blocks.5.mlp.fc2.bias', 'module.blocks.5.mlp.fc2.step_size', 'module.blocks.5.mlp.fc2.b_w', 'module.blocks.6.norm1.weight', 'module.blocks.6.norm1.bias', 'module.blocks.6.attn.qkv.weight', 'module.blocks.6.attn.qkv.bias', 'module.blocks.6.attn.qkv.step_size', 'module.blocks.6.attn.qkv.b_w', 'module.blocks.6.attn.proj.weight', 'module.blocks.6.attn.proj.bias', 'module.blocks.6.attn.proj.step_size', 'module.blocks.6.attn.proj.b_w', 'module.blocks.6.norm2.weight', 'module.blocks.6.norm2.bias', 'module.blocks.6.mlp.fc1.weight', 'module.blocks.6.mlp.fc1.bias', 'module.blocks.6.mlp.fc1.step_size', 'module.blocks.6.mlp.fc1.b_w', 'module.blocks.6.mlp.fc2.weight', 'module.blocks.6.mlp.fc2.bias', 'module.blocks.6.mlp.fc2.step_size', 'module.blocks.6.mlp.fc2.b_w', 'module.blocks.7.norm1.weight', 'module.blocks.7.norm1.bias', 'module.blocks.7.attn.qkv.weight', 'module.blocks.7.attn.qkv.bias', 'module.blocks.7.attn.qkv.step_size', 'module.blocks.7.attn.qkv.b_w', 'module.blocks.7.attn.proj.weight', 'module.blocks.7.attn.proj.bias', 'module.blocks.7.attn.proj.step_size', 'module.blocks.7.attn.proj.b_w', 'module.blocks.7.norm2.weight', 'module.blocks.7.norm2.bias', 'module.blocks.7.mlp.fc1.weight', 'module.blocks.7.mlp.fc1.bias', 'module.blocks.7.mlp.fc1.step_size', 'module.blocks.7.mlp.fc1.b_w', 'module.blocks.7.mlp.fc2.weight', 'module.blocks.7.mlp.fc2.bias', 'module.blocks.7.mlp.fc2.step_size', 'module.blocks.7.mlp.fc2.b_w', 'module.blocks.8.norm1.weight', 'module.blocks.8.norm1.bias', 'module.blocks.8.attn.qkv.weight', 'module.blocks.8.attn.qkv.bias', 'module.blocks.8.attn.qkv.step_size', 'module.blocks.8.attn.qkv.b_w', 'module.blocks.8.attn.proj.weight', 'module.blocks.8.attn.proj.bias', 'module.blocks.8.attn.proj.step_size', 'module.blocks.8.attn.proj.b_w', 'module.blocks.8.norm2.weight', 'module.blocks.8.norm2.bias', 'module.blocks.8.mlp.fc1.weight', 'module.blocks.8.mlp.fc1.bias', 'module.blocks.8.mlp.fc1.step_size', 'module.blocks.8.mlp.fc1.b_w', 'module.blocks.8.mlp.fc2.weight', 'module.blocks.8.mlp.fc2.bias', 'module.blocks.8.mlp.fc2.step_size', 'module.blocks.8.mlp.fc2.b_w', 'module.blocks.9.norm1.weight', 'module.blocks.9.norm1.bias', 'module.blocks.9.attn.qkv.weight', 'module.blocks.9.attn.qkv.bias', 'module.blocks.9.attn.qkv.step_size', 'module.blocks.9.attn.qkv.b_w', 'module.blocks.9.attn.proj.weight', 'module.blocks.9.attn.proj.bias', 'module.blocks.9.attn.proj.step_size', 'module.blocks.9.attn.proj.b_w', 'module.blocks.9.norm2.weight', 'module.blocks.9.norm2.bias', 'module.blocks.9.mlp.fc1.weight', 'module.blocks.9.mlp.fc1.bias', 'module.blocks.9.mlp.fc1.step_size', 'module.blocks.9.mlp.fc1.b_w', 'module.blocks.9.mlp.fc2.weight', 'module.blocks.9.mlp.fc2.bias', 'module.blocks.9.mlp.fc2.step_size', 'module.blocks.9.mlp.fc2.b_w', 'module.blocks.10.norm1.weight', 'module.blocks.10.norm1.bias', 'module.blocks.10.attn.qkv.weight', 'module.blocks.10.attn.qkv.bias', 'module.blocks.10.attn.qkv.step_size', 'module.blocks.10.attn.qkv.b_w', 'module.blocks.10.attn.proj.weight', 'module.blocks.10.attn.proj.bias', 'module.blocks.10.attn.proj.step_size', 'module.blocks.10.attn.proj.b_w', 'module.blocks.10.norm2.weight', 'module.blocks.10.norm2.bias', 'module.blocks.10.mlp.fc1.weight', 'module.blocks.10.mlp.fc1.bias', 'module.blocks.10.mlp.fc1.step_size', 'module.blocks.10.mlp.fc1.b_w', 'module.blocks.10.mlp.fc2.weight', 'module.blocks.10.mlp.fc2.bias', 'module.blocks.10.mlp.fc2.step_size', 'module.blocks.10.mlp.fc2.b_w', 'module.blocks.11.norm1.weight', 'module.blocks.11.norm1.bias', 'module.blocks.11.attn.qkv.weight', 'module.blocks.11.attn.qkv.bias', 'module.blocks.11.attn.qkv.step_size', 'module.blocks.11.attn.qkv.b_w', 'module.blocks.11.attn.proj.weight', 'module.blocks.11.attn.proj.bias', 'module.blocks.11.attn.proj.step_size', 'module.blocks.11.attn.proj.b_w', 'module.blocks.11.norm2.weight', 'module.blocks.11.norm2.bias', 'module.blocks.11.mlp.fc1.weight', 'module.blocks.11.mlp.fc1.bias', 'module.blocks.11.mlp.fc1.step_size', 'module.blocks.11.mlp.fc1.b_w', 'module.blocks.11.mlp.fc2.weight', 'module.blocks.11.mlp.fc2.bias', 'module.blocks.11.mlp.fc2.step_size', 'module.blocks.11.mlp.fc2.b_w', 'module.norm.weight', 'module.norm.bias', 'module.head.weight', 'module.head.bias', 'module.head.step_size', 'module.head.b_w'])
